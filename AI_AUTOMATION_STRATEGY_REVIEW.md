# AI Automation Strategy Review
## Analysis of Symphony's Invariants System for Full AI Automation with Human Supervision

**Document Version:** 1.0  
**Review Date:** 2026-01-31  
**Scope:** AI-Native Regulatory Machine Assessment  
**Focus:** Gaps, Weaknesses, and Improvement Recommendations

---

## Executive Summary

**Overall Assessment:** ✅ **STRONG FOUNDATION with 7 CRITICAL GAPS**

Your invariants system is **exceptionally mature** for a Phase-0 project. You have **105 implemented invariants** with mechanical verification, which puts you far ahead of typical financial infrastructure projects. However, for **full AI automation with human supervision**, you need specific invariants that bridge AI agent actions to human accountability.

**Key Strengths:**
1. ✅ Comprehensive DB-layer enforcement (outbox, migrations, privileges)
2. ✅ Evidence-first posture (append-only ledgers, signing hooks)
3. ✅ Mechanical verification (not manual checklists)
4. ✅ Clear ownership model (team-db, team-platform, team-security)

**Critical Gaps for AI Automation:**
1. ❌ No AI agent attestation/fingerprinting invariant
2. ❌ No deterministic rollback path requirement for AI-generated changes
3. ❌ No human-in-the-loop approval trail for AI actions
4. ❌ No AI guardrails enforcement (PII masking, prompt injection detection)
5. ❌ No autonomous compliance reporting invariant
6. ❌ No Kubernetes policy enforcement layer
7. ❌ No AI-generated code provenance tracking

---

## Part 1: Current State Assessment

### 1.1 What You Have (Strengths)

**Database Layer (World-Class):**
- INV-001 to INV-015: Migration immutability, outbox semantics, lease fencing
- INV-005 to INV-010: Deny-by-default privileges, NOLOGIN roles, no runtime DDL
- INV-014: Append-only attempts (critical for AI audit trails)

**Evidence & Compliance:**
- INV-090 to INV-095: Business foundation hooks (billing, proofs, correlation)
- INV-103: Evidence pack signing/anchoring hooks
- INV-105: Remediation trace requirement

**Security Posture:**
- INV-073: Security plane guardrails (secrets/deps/config/code)
- INV-101: Semgrep SAST baseline
- INV-104: PUBLIC privilege hygiene

**Governance:**
- INV-067: Baseline change governance (migration + ADR)
- INV-075: Compliance manifest completeness
- INV-097: Expand/contract migration policy

### 1.2 What You're Missing (For AI Automation)

**AI Agent Layer (Non-Existent):**
- No invariant requiring AI agent identity on generated artifacts
- No invariant linking AI actions to human approvers
- No invariant enforcing AI output validation before execution

**Rollback Safety (Partially Present):**
- INV-097 enforces expand/contract, but doesn't require AI to generate rollback scripts
- No invariant ensuring AI-generated migrations are bidirectionally safe

**Compliance Automation (Declared but Not Enforced):**
- INV-106, INV-107, INV-108 are roadmap (payment finality, PII decoupling, rail truth-anchor)
- No autonomous evidence generation invariant

**Runtime Protection (Missing):**
- No Kubernetes policy layer (Kyverno/OPA)
- No AI guardrails enforcement (Guardrails AI / NeMo Guardrails)
- No runtime behavior monitoring (Falco eBPF)

---

## Part 2: Critical Gaps for AI Automation

### GAP 1: AI Agent Attestation & Identity

**Problem:**
Your current system can't prove **which AI agent** (or which human via which AI agent) performed an action.

**What's Missing:**
An invariant that requires every AI-initiated change to be signed with:
- AI agent identity (agent_id, model_version, prompt_hash)
- Human approver identity (user_id, approval_timestamp)
- Change context (why, what, when)

**Recommended Invariant:**

```yaml
- id: INV-115
  aliases: ["I-AI-ATTEST-01"]
  status: roadmap
  severity: P0
  title: "AI-Agent Attestation Required for Generated Artifacts"
  owners: ["team-platform", "team-security"]
  sla_days: 7
  
  description: |
    Every database migration, policy change, or infrastructure modification
    generated by an AI agent must include an attestation record containing:
    - agent_id (e.g., "codex-cli-v2.1.0")
    - model_version (e.g., "claude-sonnet-4-20250514")
    - prompt_hash (SHA-256 of the prompt that generated the artifact)
    - human_approver_id (user who approved the AI output)
    - approval_timestamp
    - approval_method (e.g., "PLANS.md review", "inline approval")
  
  rationale: |
    For BoZ regulatory compliance, every system change must be traceable
    to a human decision-maker. AI agents are tools, not autonomous actors.
    This invariant ensures auditability and accountability.
  
  enforcement: |
    1. Migration files must include special comment block:
       -- AI-GENERATED: agent_id=codex-cli-v2.1.0, model=claude-sonnet-4, 
       --               prompt_hash=abc123, approver=user@symphony.zm,
       --               approved_at=2026-01-31T12:00:00Z
    
    2. CI gate: scripts/audit/verify_ai_attestation.sh
       - Scans all migrations/policies/k8s-manifests for AI-GENERATED marker
       - Validates attestation completeness
       - Fails if AI-generated artifact lacks attestation
  
  verification: "scripts/audit/verify_ai_attestation.sh; wired via scripts/audit/run_invariants_fast_checks.sh"
  
  acceptance_criteria:
    - [ ] All AI-generated migrations include attestation comment
    - [ ] Attestation includes all required fields (agent_id, model, prompt_hash, approver)
    - [ ] CI gate blocks merges without valid attestation
    - [ ] Evidence ledger captures attestation for audit queries
```

**Implementation Script:**

```bash
#!/bin/bash
# scripts/audit/verify_ai_attestation.sh

set -euo pipefail

echo "Checking for AI-generated artifacts without attestation..."

# Find all migration files created in last 30 days
RECENT_MIGRATIONS=$(find schema/migrations -name "*.sql" -mtime -30)

for migration in $RECENT_MIGRATIONS; do
    # Check if file contains AI-GENERATED marker
    if grep -q "-- AI-GENERATED:" "$migration"; then
        # Validate attestation completeness
        if ! grep -q "agent_id=" "$migration"; then
            echo "ERROR: $migration missing agent_id in attestation"
            exit 1
        fi
        if ! grep -q "model=" "$migration"; then
            echo "ERROR: $migration missing model in attestation"
            exit 1
        fi
        if ! grep -q "prompt_hash=" "$migration"; then
            echo "ERROR: $migration missing prompt_hash in attestation"
            exit 1
        fi
        if ! grep -q "approver=" "$migration"; then
            echo "ERROR: $migration missing approver in attestation"
            exit 1
        fi
        if ! grep -q "approved_at=" "$migration"; then
            echo "ERROR: $migration missing approved_at timestamp"
            exit 1
        fi
        echo "✓ $migration has valid AI attestation"
    fi
done

echo "✓ All AI-generated artifacts have valid attestations"
```

### GAP 2: Deterministic Rollback Path

**Problem:**
Your expand/contract policy (INV-097) prevents immediate breakage, but doesn't guarantee **AI-generated changes are reversible**.

**What's Missing:**
An invariant requiring AI agents to generate **both forward and backward scripts** simultaneously, with CI verification that they're bidirectionally safe.

**Recommended Invariant:**

```yaml
- id: INV-116
  aliases: ["I-AI-ROLLBACK-01"]
  status: roadmap
  severity: P0
  title: "AI-Generated Changes Must Include Verified Rollback Path"
  owners: ["team-db", "team-platform"]
  sla_days: 7
  
  description: |
    Every AI-generated database migration or infrastructure change must
    include a deterministic rollback mechanism verified by CI:
    
    - For migrations: Explicit DOWN script or CONTRACT phase
    - For K8s changes: Previous state snapshot + revert command
    - For policy changes: Policy version rollback pointer
  
  rationale: |
    With a skeleton crew, you cannot afford to debug rollbacks manually.
    AI agents must prove their changes are reversible before execution.
  
  enforcement: |
    1. Migration pairs: For every XXX_up.sql, require XXX_down.sql
    2. CI test: Apply up, verify state, apply down, verify original state
    3. K8s: Store previous manifest in Git, test revert before prod
  
  verification: "scripts/db/verify_rollback_path.sh; wired via scripts/db/verify_invariants.sh"
  
  acceptance_criteria:
    - [ ] Every AI-generated migration has corresponding rollback script
    - [ ] CI tests both directions (up → down → original state)
    - [ ] Rollback scripts are mechanically validated, not assumed
```

**Implementation:**

```bash
#!/bin/bash
# scripts/db/verify_rollback_path.sh

set -euo pipefail

echo "Verifying rollback paths for AI-generated migrations..."

MIGRATIONS=$(find schema/migrations -name "*_up.sql" -mtime -30)

for up_migration in $MIGRATIONS; do
    # Check if AI-generated
    if grep -q "-- AI-GENERATED:" "$up_migration"; then
        # Expect corresponding _down.sql
        down_migration="${up_migration/_up.sql/_down.sql}"
        
        if [ ! -f "$down_migration" ]; then
            echo "ERROR: $up_migration has no rollback script"
            echo "       Expected: $down_migration"
            exit 1
        fi
        
        # Test bidirectional safety
        echo "Testing: $up_migration ↔ $down_migration"
        
        # Apply up
        psql -f "$up_migration" > /dev/null
        UP_STATE=$(psql -t -c "SELECT md5(string_agg(tablename::text, ',' ORDER BY tablename)) FROM pg_tables WHERE schemaname='public'")
        
        # Apply down
        psql -f "$down_migration" > /dev/null
        DOWN_STATE=$(psql -t -c "SELECT md5(string_agg(tablename::text, ',' ORDER BY tablename)) FROM pg_tables WHERE schemaname='public'")
        
        # Reapply up
        psql -f "$up_migration" > /dev/null
        REUP_STATE=$(psql -t -c "SELECT md5(string_agg(tablename::text, ',' ORDER BY tablename)) FROM pg_tables WHERE schemaname='public'")
        
        if [ "$UP_STATE" != "$REUP_STATE" ]; then
            echo "ERROR: Rollback not idempotent for $up_migration"
            exit 1
        fi
        
        echo "✓ $up_migration has verified rollback path"
    fi
done

echo "✓ All AI-generated migrations have valid rollback paths"
```

### GAP 3: Human-in-the-Loop Approval Trail

**Problem:**
You have attestation (GAP 1 fix), but no **evidence ledger** capturing the human approval chain.

**What's Missing:**
An append-only table tracking every AI action approval with:
- What was proposed
- Who approved it
- When it was approved
- What was the outcome

**Recommended Implementation:**

```sql
-- schema/migrations/0025_ai_approval_ledger.sql
-- AI-GENERATED: agent_id=human-architect, model=manual,
--               approver=architect@symphony.zm, approved_at=2026-01-31

CREATE TABLE ai_approval_ledger (
    approval_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    
    -- AI Agent Identity
    agent_id TEXT NOT NULL,
    model_version TEXT NOT NULL,
    prompt_hash TEXT NOT NULL,
    
    -- Human Approver
    approver_user_id TEXT NOT NULL,
    approver_email TEXT NOT NULL,
    approval_method TEXT NOT NULL,  -- 'PLANS_MD_REVIEW', 'INLINE_APPROVAL', 'EMERGENCY_OVERRIDE'
    
    -- What Changed
    artifact_type TEXT NOT NULL,  -- 'MIGRATION', 'POLICY', 'K8S_MANIFEST', 'CODE'
    artifact_path TEXT NOT NULL,
    artifact_hash TEXT NOT NULL,  -- SHA-256 of artifact
    
    -- Context
    change_description TEXT NOT NULL,
    git_commit_sha TEXT,
    
    -- Outcome
    execution_status TEXT,  -- 'PENDING', 'APPLIED', 'FAILED', 'ROLLED_BACK'
    executed_at TIMESTAMPTZ,
    
    -- Audit
    approved_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Append-only enforcement
CREATE TRIGGER prevent_ai_approval_mutation
BEFORE UPDATE OR DELETE ON ai_approval_ledger
FOR EACH ROW EXECUTE FUNCTION deny_update_delete();

-- Indexes
CREATE INDEX ix_ai_approvals_approver ON ai_approval_ledger (approver_user_id, approved_at DESC);
CREATE INDEX ix_ai_approvals_agent ON ai_approval_ledger (agent_id, approved_at DESC);
CREATE INDEX ix_ai_approvals_artifact ON ai_approval_ledger (artifact_hash);

-- Privilege: only automation user can INSERT
GRANT INSERT ON ai_approval_ledger TO automation_bot;
REVOKE UPDATE, DELETE ON ai_approval_ledger FROM automation_bot;
```

**Corresponding Invariant:**

```yaml
- id: INV-117
  aliases: ["I-AI-APPROVAL-01"]
  status: roadmap
  severity: P0
  title: "Human Approval Trail Required for AI Actions"
  owners: ["team-platform", "team-security"]
  sla_days: 7
  
  description: |
    Every AI-generated artifact execution must create a record in
    ai_approval_ledger proving human oversight.
  
  verification: "scripts/audit/verify_ai_approval_ledger.sh"
```

### GAP 4: AI Guardrails Enforcement

**Problem:**
No runtime protection against AI agents **leaking PII** (TPINs, NRCs, account numbers) or being exploited via **prompt injection**.

**What's Missing:**
A Kubernetes policy layer that **intercepts all AI outputs** before they're logged or executed.

**Recommended Stack:**

**Layer 1: Guardrails AI (Output Filtering)**

```yaml
# k8s/deployments/guardrails-ai-sidecar.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: guardrails-config
data:
  config.yml: |
    filters:
      - name: pii_masking
        patterns:
          - regex: '\b\d{11}\b'  # TPIN format (11 digits)
            replacement: '[TPIN_REDACTED]'
          - regex: '\b\d{9}\b'   # NRC format (9 digits)
            replacement: '[NRC_REDACTED]'
          - regex: '\b\d{10,16}\b'  # Account/card numbers
            replacement: '[ACCOUNT_REDACTED]'
      
      - name: prompt_injection_detection
        rules:
          - detect: 'ignore previous instructions'
            action: BLOCK
          - detect: 'system:'
            action: BLOCK
          - detect: 'DROP TABLE'
            action: BLOCK

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-agent-with-guardrails
spec:
  template:
    spec:
      containers:
      - name: ai-agent
        image: symphony/codex-cli:latest
        env:
        - name: GUARDRAILS_ENDPOINT
          value: "http://localhost:8001"
      
      - name: guardrails-sidecar
        image: guardrailsai/guardrails-server:latest
        volumeMounts:
        - name: config
          mountPath: /config
      
      volumes:
      - name: config
        configMap:
          name: guardrails-config
```

**Layer 2: Kyverno Policy (Enforcement)**

```yaml
# k8s/policies/require-guardrails-sidecar.yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-ai-guardrails
spec:
  validationFailureAction: enforce
  rules:
  - name: require-guardrails-sidecar-in-prod
    match:
      any:
      - resources:
          kinds: ["Deployment"]
          namespaces: ["symphony-prod"]
          selector:
            matchLabels:
              ai-agent: "true"
    validate:
      message: "AI agents in production must have guardrails sidecar"
      pattern:
        spec:
          template:
            spec:
              containers:
              - name: guardrails-sidecar
                image: "guardrailsai/guardrails-server:*"
```

**Corresponding Invariant:**

```yaml
- id: INV-118
  aliases: ["I-AI-GUARDRAILS-01"]
  status: roadmap
  severity: P0
  title: "AI Guardrails Sidecar Required in Production"
  owners: ["team-security", "team-platform"]
  sla_days: 7
  
  description: |
    All AI agent pods in production namespace must include guardrails
    sidecar that filters PII and detects prompt injection before outputs
    reach logs, databases, or external systems.
  
  enforcement: |
    - Kyverno policy blocks deployment without sidecar
    - Guardrails AI config includes TPIN/NRC/account masking
    - Evidence ledger captures filtered vs. raw output metrics
  
  verification: "scripts/k8s/verify_guardrails_policy.sh"
  
  acceptance_criteria:
    - [ ] Kyverno policy deployed and enforcing
    - [ ] Guardrails config includes all PII patterns
    - [ ] Test proves TPIN in AI output gets masked before logging
    - [ ] Metrics show filter hit rate
```

### GAP 5: Autonomous Compliance Reporting

**Problem:**
You have compliance manifest (INV-075), but no **automated daily evidence generation** for regulators.

**What's Missing:**
A nightly job that:
- Queries evidence_events ledger
- Generates signed compliance report
- Hashes report into immutable chain
- Makes report available to BoZ "observability seat"

**Recommended Invariant:**

```yaml
- id: INV-119
  aliases: ["I-AUTO-COMPLY-01"]
  status: roadmap
  severity: P0
  title: "Autonomous Daily Compliance Evidence Generation"
  owners: ["team-platform", "team-compliance"]
  sla_days: 14
  
  description: |
    A daily automated job must generate a compliance evidence pack
    containing:
    - Invariant verification results (all 105+ checks)
    - Evidence events summary (by type, severity)
    - AI approval ledger digest
    - Security incidents (if any)
    - Signing metadata (git SHA, timestamp, signer identity)
  
  enforcement: |
    - Kubernetes CronJob: 01:00 UTC daily
    - Job queries evidence_events, ai_approval_ledger, invariant_results
    - Generates JSON report + detached signature
    - Uploads to BoZ-accessible S3 bucket (or WORM storage)
    - Records report hash in evidence ledger
  
  verification: "scripts/compliance/verify_daily_report_generation.sh"
  
  acceptance_criteria:
    - [ ] CronJob runs successfully every day
    - [ ] Report includes all required sections
    - [ ] Report is digitally signed
    - [ ] Report hash stored in immutable ledger
    - [ ] BoZ can verify signature independently
```

**Implementation:**

```yaml
# k8s/cronjobs/daily-compliance-report.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: daily-compliance-report
spec:
  schedule: "0 1 * * *"  # 01:00 UTC daily
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: report-generator
            image: symphony/compliance-reporter:latest
            env:
            - name: DB_CONNECTION
              valueFrom:
                secretKeyRef:
                  name: db-readonly-creds
                  key: connection_string
            - name: SIGNING_KEY_ID
              value: "symphony-evidence-2026"
            - name: S3_BUCKET
              value: "s3://symphony-compliance-zambia"
            command:
            - /bin/bash
            - -c
            - |
              set -e
              
              REPORT_DATE=$(date +%Y-%m-%d)
              REPORT_FILE="compliance-report-${REPORT_DATE}.json"
              
              # Generate report
              python3 /app/generate_compliance_report.py \
                --date "$REPORT_DATE" \
                --output "/tmp/$REPORT_FILE"
              
              # Sign report
              gpg --detach-sign --armor \
                --local-user "$SIGNING_KEY_ID" \
                "/tmp/$REPORT_FILE"
              
              # Upload to S3
              aws s3 cp "/tmp/$REPORT_FILE" "$S3_BUCKET/"
              aws s3 cp "/tmp/${REPORT_FILE}.asc" "$S3_BUCKET/"
              
              # Record in evidence ledger
              REPORT_HASH=$(sha256sum "/tmp/$REPORT_FILE" | awk '{print $1}')
              psql -c "INSERT INTO compliance_report_ledger (report_date, report_hash, s3_key) VALUES ('$REPORT_DATE', '$REPORT_HASH', '$REPORT_FILE')"
              
              echo "✓ Compliance report generated: $REPORT_FILE"
          restartPolicy: OnFailure
```

### GAP 6: Kubernetes Policy Layer (Missing Entirely)

**Problem:**
You have excellent **database-layer enforcement**, but no **infrastructure-layer enforcement**. Developers (or AI agents) can deploy pods that bypass your invariants.

**What's Missing:**
A policy engine (Kyverno or OPA) that enforces invariants at the **Kubernetes API level** before pods start.

**Recommended Policies:**

**Policy 1: No Privileged Pods**
```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: deny-privileged-pods
spec:
  validationFailureAction: enforce
  rules:
  - name: deny-privileged
    match:
      any:
      - resources:
          kinds: ["Pod"]
    validate:
      message: "Privileged pods are not allowed"
      pattern:
        spec:
          containers:
          - =(securityContext):
              =(privileged): false
```

**Policy 2: Require Resource Limits**
```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-resource-limits
spec:
  validationFailureAction: enforce
  rules:
  - name: require-limits
    match:
      any:
      - resources:
          kinds: ["Deployment"]
    validate:
      message: "Deployments must define resource limits"
      pattern:
        spec:
          template:
            spec:
              containers:
              - resources:
                  limits:
                    memory: "?*"
                    cpu: "?*"
```

**Policy 3: Require Secrets from OpenBao (Not Inline)**
```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-external-secrets
spec:
  validationFailureAction: enforce
  rules:
  - name: no-inline-secrets
    match:
      any:
      - resources:
          kinds: ["Deployment", "StatefulSet"]
    validate:
      message: "Secrets must come from OpenBao, not inline env vars"
      deny:
        conditions:
          any:
          - key: "{{ request.object.spec.template.spec.containers[].env[].value }}"
            operator: Contains
            value: "password"
          - key: "{{ request.object.spec.template.spec.containers[].env[].value }}"
            operator: Contains
            value: "secret"
```

**Corresponding Invariant:**

```yaml
- id: INV-120
  aliases: ["I-K8S-POLICY-01"]
  status: roadmap
  severity: P0
  title: "Kubernetes Policy Engine Enforces Sovereign Rules"
  owners: ["team-platform", "team-security"]
  sla_days: 14
  
  description: |
    Kyverno (or OPA Gatekeeper) must be deployed and enforcing policies:
    - No privileged pods
    - Resource limits required
    - Secrets from OpenBao only (no inline)
    - AI agents require guardrails sidecar
    - PII-handling pods require network policies
  
  verification: "scripts/k8s/verify_policy_engine.sh"
```

### GAP 7: AI-Generated Code Provenance

**Problem:**
You can attest that AI generated an artifact, but you can't **prove which version of which code** the AI was operating against.

**What's Missing:**
A linkage between AI outputs and the **exact repo state** the AI had access to during generation.

**Recommended Solution:**

```yaml
- id: INV-121
  aliases: ["I-AI-PROVENANCE-01"]
  status: roadmap
  severity: P1
  title: "AI-Generated Artifacts Include Code Provenance"
  owners: ["team-platform"]
  sla_days: 14
  
  description: |
    Every AI-generated artifact must include provenance metadata:
    - repo_commit_sha: The exact Git commit AI was operating against
    - repo_branch: The branch AI had access to
    - context_files: List of files AI considered (hashed)
    - generation_timestamp: When artifact was generated
  
  rationale: |
    If AI generates a migration that breaks something, we need to know
    what context the AI was working with to reproduce the issue.
  
  enforcement: |
    Migration header includes:
    -- AI-PROVENANCE: repo_sha=abc123, branch=main,
    --                context_files=[sha256:def456, sha256:ghi789],
    --                generated_at=2026-01-31T12:00:00Z
  
  verification: "scripts/audit/verify_ai_provenance.sh"
```

---

## Part 3: Recommended Immediate Actions

### Priority 1 (This Sprint) — AI Attestation Foundation

**Action Items:**
1. ✅ Add INV-115 (AI Agent Attestation) to manifest
2. ✅ Implement `scripts/audit/verify_ai_attestation.sh`
3. ✅ Create `ai_approval_ledger` table (INV-117 dependency)
4. ✅ Update Codex CLI to emit attestation headers automatically
5. ✅ Wire attestation check into CI pipeline

**Why Critical:**
Without attestation, you **cannot prove human oversight** to BoZ auditors.

### Priority 2 (Next Sprint) — Rollback Safety

**Action Items:**
1. ✅ Add INV-116 (Deterministic Rollback Path) to manifest
2. ✅ Implement `scripts/db/verify_rollback_path.sh`
3. ✅ Update migration template to include `_up.sql` and `_down.sql` pairs
4. ✅ Add CI test for bidirectional migration safety

**Why Critical:**
With a skeleton crew, you **cannot afford manual rollback debugging**.

### Priority 3 (Month 2) — AI Guardrails

**Action Items:**
1. ✅ Deploy Guardrails AI or NeMo Guardrails
2. ✅ Create PII masking config (TPIN, NRC, account patterns)
3. ✅ Deploy Kyverno policy requiring guardrails sidecar
4. ✅ Add INV-118 (AI Guardrails) to manifest
5. ✅ Test: Prove TPIN in AI output gets masked

**Why Critical:**
One PII leak to logs = **regulatory incident**. Prevention is mandatory.

### Priority 4 (Month 3) — Kubernetes Policy Layer

**Action Items:**
1. ✅ Deploy Kyverno or OPA Gatekeeper
2. ✅ Implement 5 core policies (privileged, limits, secrets, guardrails, network)
3. ✅ Add INV-120 (K8s Policy Engine) to manifest
4. ✅ Implement `scripts/k8s/verify_policy_engine.sh`

**Why Critical:**
Database-layer enforcement alone **cannot prevent infrastructure bypass**.

---

## Part 4: Strengths to Preserve

### 1. Mechanical Verification (Not Checklists)

**What You're Doing Right:**
Every invariant has a **script** that proves compliance, not a manual review checklist.

**Example (INV-014):**
```
Verification: "schema/migrations/0001_init.sql append-only trigger + 
               scripts/db/ci_invariant_gate.sql"
```

This is **exactly** what AI automation needs. Keep this discipline rigorously.

### 2. Append-Only Forensics

**What You're Doing Right:**
- `payment_outbox_attempts` is append-only (INV-014)
- Evidence packs include signing/anchoring (INV-103)
- Remediation trace required (INV-105)

**Why This Matters:**
AI agents will make mistakes. When they do, your append-only ledgers let you **reconstruct exactly what happened** without trust assumptions.

### 3. Clear Ownership Model

**What You're Doing Right:**
```yaml
owners: ["team-db", "team-platform", "team-security"]
```

Every invariant has an owner. This maps cleanly to **human accountability** in your AI-native model.

### 4. Evidence-First Culture

**What You're Doing Right:**
You're not just "building a payments system" — you're building a **self-documenting organism** that generates its own audit trail.

**Critical for AI:**
AI agents can't be "trusted" — they can only be **audited**. Your evidence-first posture makes AI automation safe.

---

## Part 5: Weaknesses to Address

### WEAKNESS 1: Roadmap Invariants Not Prioritized

**Problem:**
You have **critical invariants in roadmap status** (INV-106, INV-107, INV-108) without clear activation timeline.

**Example:**
```yaml
- id: INV-106
  title: "Payment finality / instruction irrevocability"
  status: roadmap
  verification: "Phase-1 activation: ..."
```

**Issue:**
"Phase-1 activation" is vague. When does Phase-1 start? What triggers it?

**Recommendation:**
Add explicit **activation criteria** to roadmap invariants:

```yaml
- id: INV-106
  status: roadmap
  activation_trigger: "First production instruction processed"
  activation_deadline: "2026-Q2"
  blocking_invariants: ["INV-011", "INV-012", "INV-013"]  # Must be implemented first
```

### WEAKNESS 2: No AI-Specific Severity Classification

**Problem:**
Your severity model (P0, P1) works for DB/security invariants, but doesn't account for **AI automation risks**.

**Example Missing:**
- P0-AI: Invariant prevents AI from causing irreversible harm
- P1-AI: Invariant ensures AI actions are auditable
- P2-AI: Invariant improves AI efficiency but not safety

**Recommendation:**
Add AI-specific severity to new invariants:

```yaml
- id: INV-115
  severity: P0-AI  # AI-critical: prevents unaccountable AI actions
  
- id: INV-119
  severity: P1-AI  # AI-important: ensures AI auditability
```

### WEAKNESS 3: No Performance Budgets for AI Verification

**Problem:**
Mechanical verification is great, but if CI takes **30 minutes to run**, AI agents will bypass it.

**Issue:**
No invariants about **verification performance**.

**Recommendation:**

```yaml
- id: INV-122
  aliases: ["I-CI-PERF-01"]
  status: roadmap
  severity: P1
  title: "CI Invariant Checks Complete in < 5 Minutes"
  owners: ["team-platform"]
  
  description: |
    Total CI runtime for all invariant checks must stay under 5 minutes
    to maintain developer (and AI agent) flow.
  
  enforcement: |
    - CI job times out at 6 minutes
    - Slow checks flagged for optimization
    - Parallel execution where safe
  
  verification: "scripts/audit/verify_ci_performance.sh"
```

### WEAKNESS 4: No Drift Detection for Kubernetes State

**Problem:**
You have excellent **database drift detection** (INV-004), but no equivalent for **Kubernetes state drift**.

**Example:**
If someone manually edits a deployment (bypassing GitOps), you won't know until it breaks.

**Recommendation:**

```yaml
- id: INV-123
  aliases: ["I-K8S-DRIFT-01"]
  status: roadmap
  severity: P1
  title: "Kubernetes State Must Not Drift from Git"
  owners: ["team-platform"]
  
  description: |
    ArgoCD must detect and remediate any K8s resource that drifts from
    Git-declared state within 5 minutes.
  
  enforcement: |
    - ArgoCD auto-sync enabled
    - Manual changes trigger alert + auto-revert
    - Evidence generated for every drift event
  
  verification: "scripts/k8s/verify_argocd_sync_status.sh"
```

---

## Part 6: Integration with Existing Roadmap

### How These Gaps Fit Into Symphony Roadmap v3.0

**Phase 0 Additions:**
- ✅ TSK-P0-006: Add AI Attestation Invariant (INV-115)
- ✅ TSK-P0-007: Add Rollback Path Invariant (INV-116)
- ✅ TSK-P0-008: Design AI Approval Ledger Schema

**Phase 1 Additions:**
- ✅ TSK-P1-006: Implement AI Approval Ledger Migration
- ✅ TSK-P1-007: Deploy Guardrails AI Sidecar
- ✅ TSK-P1-008: Implement Attestation Verification Script

**Phase 2 Additions:**
- ✅ TSK-P2-006: Deploy Kyverno Policy Engine
- ✅ TSK-P2-007: Implement Autonomous Compliance Reporting
- ✅ TSK-P2-008: Add K8s Drift Detection

---

## Part 7: Specific FOSS Stack Recommendations

Based on your desire for "Enterprise-Equivalent FOSS":

### Layer 1: Secret Management

**Current:** OpenBao ✅ (Correct choice)

**Enhancement:**
- Add Kubernetes Secrets Store CSI Driver for pod-level secret injection
- Integrate with Guardrails AI for secret detection in AI outputs

### Layer 2: GitOps

**Current:** Not specified ❌

**Recommendation:** ArgoCD + Flux (dual engine)
- **ArgoCD:** Primary sync engine for K8s manifests
- **Flux:** Helm chart lifecycle management
- **Why both:** ArgoCD for visibility, Flux for Helm native support

### Layer 3: AI Guardrails

**Current:** Not implemented ❌

**Recommendation:** Guardrails AI (primary) + NeMo Guardrails (backup)
- **Guardrails AI:** Better open-source community, easier deployment
- **NeMo Guardrails:** NVIDIA-backed, better for multi-model scenarios

### Layer 4: Policy Engine

**Current:** Not implemented ❌

**Recommendation:** Kyverno (preferred) or OPA Gatekeeper
- **Kyverno:** Simpler YAML, better for team with limited K8s experience
- **OPA:** More powerful, better if you already have Rego expertise (you do, for policy-as-code)

**Decision Matrix:**
| Factor | Kyverno | OPA Gatekeeper |
|--------|---------|----------------|
| Ease of use | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ |
| Power | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| Symphony fit | Use Kyverno | Use OPA if policy-as-code team writes policies |

**Recommendation:** Start with **Kyverno** for faster time-to-value.

### Layer 5: Observability

**Current:** Not specified ❌

**Recommendation:** Grafana LGTM Stack (Loki, Grafana, Tempo, Mimir)
- **Loki:** Log aggregation (replaces Elasticsearch, lighter weight)
- **Grafana:** Dashboards + alerting
- **Tempo:** Distributed tracing
- **Mimir:** Long-term metrics storage

### Layer 6: Runtime Security

**Current:** Semgrep for SAST ✅

**Enhancement:** Add Falco for runtime behavior monitoring
- **Falco:** Uses eBPF to detect suspicious pod behavior
- **Example:** Alert if AI agent pod tries to read `/etc/shadow`

### Layer 7: Code Integrity

**Current:** Not specified ❌

**Recommendation:** Gitea (self-hosted) or Forgejo
- **Why self-hosted:** Sovereign requirement (BoZ may require on-premises Git)
- **Gitea vs Forgejo:** Forgejo is community fork, more active development

---

## Part 8: Final Recommendations

### Immediate Actions (This Week)

1. ✅ **Add INV-115, INV-116, INV-117** to manifest (AI attestation, rollback, approval trail)
2. ✅ **Create `ai_approval_ledger` table** in next migration
3. ✅ **Update Codex CLI** to emit attestation headers automatically
4. ✅ **Write verification scripts** for new invariants
5. ✅ **Wire into CI pipeline** (blocking gates)

### Short-Term (Month 1-2)

6. ✅ **Deploy Guardrails AI** with TPIN/NRC/account masking
7. ✅ **Add INV-118** (AI Guardrails) to manifest
8. ✅ **Test PII masking** end-to-end
9. ✅ **Deploy Kyverno** with 5 core policies
10. ✅ **Add INV-120** (K8s Policy Engine) to manifest

### Medium-Term (Month 3-6)

11. ✅ **Implement autonomous compliance reporting** (INV-119)
12. ✅ **Deploy ArgoCD** for GitOps + drift detection (INV-123)
13. ✅ **Add Falco** for runtime security monitoring
14. ✅ **Activate roadmap invariants** (INV-106, INV-107, INV-108) with clear criteria
15. ✅ **Performance-tune CI** to stay under 5 minutes (INV-122)

---

## Conclusion

**Your invariants system is world-class.** You have 105 implemented invariants with mechanical verification — something most banks **don't have after 10 years**.

**However, for AI automation, you need 7 new invariants:**

1. **INV-115:** AI Agent Attestation (P0)
2. **INV-116:** Deterministic Rollback Path (P0)
3. **INV-117:** Human Approval Trail (P0)
4. **INV-118:** AI Guardrails Enforcement (P0)
5. **INV-119:** Autonomous Compliance Reporting (P0)
6. **INV-120:** Kubernetes Policy Engine (P0)
7. **INV-121:** AI-Generated Code Provenance (P1)

**Plus 2 operational invariants:**

8. **INV-122:** CI Performance Budget (< 5 min)
9. **INV-123:** Kubernetes State Drift Detection

**With these additions, Symphony will be the world's first truly AI-native financial infrastructure that regulators can actually trust.**

---

## Appendix A: Quick-Start AI Attestation Template

For immediate use, here's a migration template with AI attestation:

```sql
-- Migration: 0026_example_ai_generated_feature.sql
-- AI-GENERATED: agent_id=codex-cli-v2.1.0, 
--               model=claude-sonnet-4-20250514,
--               prompt_hash=sha256:abc123def456...,
--               approver=engineer@symphony.zm,
--               approved_at=2026-01-31T12:00:00Z,
--               approval_method=PLANS_MD_REVIEW
-- AI-PROVENANCE: repo_sha=abc123,
--                 branch=main,
--                 context_files=[sha256:def456, sha256:ghi789],
--                 generated_at=2026-01-31T11:55:00Z

-- Your migration DDL here
CREATE TABLE example (...);

-- Rollback path (INV-116 requirement)
-- File: 0026_example_ai_generated_feature_down.sql must exist
```

This template satisfies **INV-115, INV-116, INV-121** simultaneously.
